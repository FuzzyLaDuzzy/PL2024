import re

tokens = [
    ('SELECT', r'Select', re.IGNORECASE),
    ('ID', r'[a-zA-Z_][a-zA-Z0-9_]*', None),
    ('COMMA', r',', None),
    ('FROM', r'From', re.IGNORECASE),
    ('WHERE', r'Where', re.IGNORECASE),
    ('GREATER_EQUAL', r'>=', None),
    ('NUMBER', r'\d+', None),
]

ignore = r'\s+'

# Lexer function
def lexer(sql_query):
    token_regex = '|'.join('(?P<%s>%s)' % (name, pattern) if flags is None else '(?P<%s>%s)' % (name, pattern) for name, pattern, flags in tokens)
    ignore_regex = re.compile(ignore)
    for match in re.finditer(token_regex, sql_query):
        token_type = match.lastgroup
        token_value = match.group(token_type)
        if not ignore_regex.match(token_value):
            yield token_type, token_value

sql_query = input("Enter your SQL query: ")

for token in lexer(sql_query):
    print(token)
